{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "fuente = 'fuentes/Japan_000817_jpg.rf.5a107f013df5f690a26a1220a0f58925.jpg'\n",
    "\n",
    "class VersionesYolo(Enum):\n",
    "    YOLOV5 = \"yolov5\"\n",
    "    YOLOV7 = \"yolov7\"\n",
    "\n",
    "@dataclass\n",
    "class ModeloInfo():\n",
    "    nombre: str\n",
    "    pesos: str\n",
    "    yolo_version: VersionesYolo\n",
    "    \n",
    "modelo1 = ModeloInfo(\n",
    "    nombre='yolov5s_1',\n",
    "    pesos='corridas/mejores/exp5/weights/best.pt',\n",
    "    yolo_version=VersionesYolo.YOLOV5\n",
    ")\n",
    "modelo2 = ModeloInfo(\n",
    "    nombre='yolov5l_1',\n",
    "    pesos='corridas/mejores/exp8/weights/best.pt',\n",
    "    yolo_version=VersionesYolo.YOLOV5\n",
    ")\n",
    "modelo3 = ModeloInfo(\n",
    "    nombre='yolov5s_1',\n",
    "    pesos='corridas/mejores/exp6/weights/best.pt',\n",
    "    yolo_version=VersionesYolo.YOLOV7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['corridas/mejores/exp5/weights/best.pt'], source=fuentes/Japan_000817_jpg.rf.5a107f013df5f690a26a1220a0f58925.jpg, data=yolov5\\data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5  2022-10-15 Python-3.10.7 torch-1.12.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "custom_YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/1 C:\\Users\\enime\\Desktop\\Proyectos\\classgap\\20221003_ambiela_mateo\\proyecto_tesis\\fuentes\\Japan_000817_jpg.rf.5a107f013df5f690a26a1220a0f58925.jpg: 640x640 2 D00s, 1 D10, 206.0ms\n",
      "Speed: 1.0ms pre-process, 206.0ms inference, 7.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1myolov5\\runs\\detect\\exp3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mod = modelo1\n",
    "!python $mod.yolo_version.value/detect.py --weights $mod.pesos --source $fuente"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1100b4e16d94e1fa4a3c2cd9e932f3303ece89bcdfac8a154b6ba324856ce33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
