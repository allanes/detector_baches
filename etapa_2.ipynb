{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import six.moves.urllib as urllib\n",
    "# from xml.etree import ElementTree\n",
    "# from xml.dom import minidom\n",
    "# import collections\n",
    "\n",
    "# import os\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib as matplot\n",
    "# import seaborn as sns\n",
    "\n",
    "# import cv2\n",
    "# import random\n",
    "\n",
    "# ##########\n",
    "# import sys\n",
    "# import tarfile\n",
    "# import zipfile\n",
    "# from collections import defaultdict\n",
    "# from io import StringIO\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT =  'pretrained_models/ssd_mobilenet_v2_fpn_lite_640.pb' \n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = 'pretrained_models/crack_label_map.pbtxt'\n",
    "\n",
    "\n",
    "RUTA_RDD = \".\"\n",
    "CARPETAS_INTERES = [\"/China_Drone\", \"/China_MotorBike\", \"/Czech\", \"/India\", \"/Japan\", \"/Norway\", \"/United_States\"]\n",
    "CARPETAS_INTERES = [\"/DATA\"]\n",
    "CARPETA_SALIDA = []\n",
    "RUTA_IMAGENES = \"/train/images\"\n",
    "RUTA_ANOTACIONES_ORIGINALES = \"/train/annotations/xmls\"\n",
    "# RUTA_ANOTACIONES_SALIDA = f'{RUTA_RDD}/labels_salida'\n",
    "RUTA_ANOTACIONES_SALIDA = f'{RUTA_RDD}/DATA/labels_salida'\n",
    "ETIQUETAS_ENTRADA = [\"D00\",\"D01\",\"D10\",\"D11\",\"D20\",\"D40\",\"D43\",\"D44\", \"D50\", \"Repair\"]\n",
    "\n",
    "NUM_CLASSES = len(ETIQUETAS_ENTRADA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train yolov5s on Aquarium object detection data for 100 epochs [aroung 1000 epochs for better training and result]\n",
    "# NOTE: All the images are already pre-processed to 416 x 416 size.\n",
    "# We will be training for 100 epoch (increase it for better result) with batch size of 80\n",
    "# data.yaml also contains the information about location of Train and Validation Data. That's how you get the train data.\n",
    "# the training also requires the configuration of neural network, which is in custom_yolov5s.yaml\n",
    "# weights will be by-default stored at /content/yolov5/runs/exp2/weights/best.pt\n",
    "# time its performance\n",
    "\n",
    "# %cd yolov5\n",
    "ESCALADO_IMAGEN = 512\n",
    "cadena = f'python train.py --img {ESCALADO_IMAGEN} --batch 9 --epochs 30 --data data.yaml --weights runs/train/exp3/weights/last.pt --cfg models/custom_yolov5s.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutar:\n",
      "python ./yolov5/train.py --img 512 --batch 10 --epochs 10 --data ./data.yaml --weights pretrained_models/ssd_mobilenet_v2_fpn_lite_640.pb --cfg ./custom_yolov5s.yaml\n"
     ]
    }
   ],
   "source": [
    "ESCALADO_IMAGEN = 512\n",
    "EPOCAS = 10\n",
    "DATA_YAML = './data.yaml'\n",
    "ARCHIVO_PESOS = PATH_TO_CKPT\n",
    "# ARCHIVO_PESOS = 'runs/train/exp3/weights/last.pt'\n",
    "CONFIG_YAML = './custom_yolov5s.yaml'\n",
    "cadena = f'python ./yolov5/train.py --img {ESCALADO_IMAGEN} --batch {NUM_CLASSES} --epochs {EPOCAS} --data {DATA_YAML} --weights {ARCHIVO_PESOS} --cfg {CONFIG_YAML}'\n",
    "print('Ejecutar:')\n",
    "print(cadena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\enime\\Desktop\\Proyectos\\classgap\\20221003_ambiela_mateo\\proyecto_tesis\\yolov5\\train.py\", line 29, in <module>\n",
      "    import torch\n",
      "ModuleNotFoundError: No module named 'torch'\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/train.py --img 512 --batch 10 --epochs 10 --data ./data.yaml --weights pretrained_models/ssd_mobilenet_v2_fpn_lite_640.pb --cfg ./custom_yolov5s.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('object_detection': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cd0deddd348c527b562bd3d4c44d891f3a934129a3ca56cc41c73545b5f78dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
